\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Introduction} 
\label{sec:intro}

Many algorithms, such as SMC \citep{smc} and MCMC \citep{mcmc}, approximate a 
distribution with samples. Most such algorithms require access to a full posterior and 
may be prone to becoming stuck in local modes. In contrast, the herding algorithm introduced in 
\citet{Welling:2009a} generates samples whose moments are guaranteed to converge 
to any given collection of feasible moments. Moreover, \emph{only} the moments 
are required; a full posterior is not needed.

Since its introduction, herding has been shown to have many desirable properties.
For instance, \citet{Chen:2010a} showed that the moments converge at a rate of $O(1/T^{2})$ for 
$T$ samples, which is even faster than the $O(1/T)$ rate that would be obtained 
by sampling independently from the exact posterior. Furthermore, \citet{Bach:2012a} show that herding is 
equivalent to conditional gradient, and \citet{Huszar:2012} show that 
herding is equivalent to Bayesian quadrature. Herding was originally conceived of as a method 
for inference in Markov random fields, and this line of work has been further explored in 
\citet{Welling:2009a}, \citet{Gelfand:2010}, and \citet{Bornn:2013}.

In order to define herding, let $\sX$ be an observation space, $\phi : \sX \to \sB_{\Theta}$ a 
feature map to an inner product space, and $\bar\phi = \bE_{x \sim p}[\phi(x)]$ the empirical 
moments of some distribution. Then the herding algorithm is the following simple procedure to 
generate pseudosamples from $\sX$:
\[
x_{t} &\in \argmin_{x \in \sX} \ip{\theta_{t}}{\phi(x)} \\
\theta_{t} &= \theta_{t-1}  + \bar \phi - \phi(x_{t}).
\]
In this paper we generalize the herding algorithm to minimize $h(h) + R^{*}(u)$ via the following set of updates, which 
require only the convexity of $h$ and $R$:
\[
u_t &\in \argmin_{u} h(u) + \ip{\theta_t}{u} \\
\theta_{t+1} &\in \argmax_{\theta} \ip{\theta}{\hat{u}_t} - R(\theta),
\]
where $\hat{u}_t$ is a certain weighted average of $u_1,\ldots,u_t$. Our 
algorithm is described in more detail in Section~\ref{sec:algorithm}. This 
generalization has several advantages:
\begin{itemize}
\item It allows us to cast herding in the framework of mirror descent \cite{Beck:2003}, 
      which lets us better understand its convergence properties.
\item It allows us to obtain generalizations of herding for infinite 
      dimensional spaces that apply in cases where standard herding does not.
\item It makes the known connections between herding, subgradient, and 
      conditional gradient methods more clear. 
\end{itemize}
In particular, while it was known that herding was a form of conditional 
gradient descent \cite{Bach:2012a} and hence (via the relationship in \citet{Bach:2012b}) also 
a form of subgradient descent, our framework exposes all three algorithms 
as special cases. A full table outlining the relationships for various choices of 
$h$ and $R$ is given in Table~\ref{tab:connections}.

In summary, we introduce a novel gradient descent algorithm to investigate herding and its generalizations, and make the following contributions:
\begin{itemize}
\item In Section \ref{sec:algorithm} we introduce a pair of convex optimization algorithms, which we call primal and dual boosted mirror descent (\primal and \dual). We show how \primal and \dual relate to conditional gradient (\cgd) and mirror descent (\md). 
\item We then use \dual in Section \ref{sec:herding} to define two classes of generalized herding algorithms. Connections with the ``learning'' interpretation of herding are made by showing how to obtain herding as the limit of an entropically normalized case of \dual. 
\item Section \ref{sec:proofs} presents convergence rates for \primal and \dual. As special cases, we recover a $O(\log T/ T)$ convergence rate for classical herding and a $O(1/T)$ rate for weighted herding. Both of these results apply to the infinite dimensional case. 
\item In Section \ref{sec:lower-bounds} we prove a matching lower bound to the upper bound given in Section \ref{sec:proofs}, showing that any ``sparse'' herding-like method cannot converge faster than $O(1/T)$ in the the infinite dimensional case.% and that herding converges at the slower $O(\log T / T)$ rate.
%\item Finally, in section \ref{sec:chen-proofs} we generalize the $O(1/T^{2})$ convergence proof of \citet{Chen:2010a} to a class of herding-like algorithms derived from \bmd. 
\end{itemize}


\end{document}
