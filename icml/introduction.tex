\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Introduction} 
\label{sec:intro}

Many algorithms, such as SMC \citep{smc} and MCMC \citep{mcmc}, approximate a 
distribution by samples. Most such algorithms require access to a full posterior and 
may be prone to becoming stuck local modes. In contrast, the herding algorithm introduced in 
\citet{Welling:2009a} generates samples whose moments are guaranteed to converge 
to any given collection of feasible moments. Moreover, \emph{only} the moments 
are required; a full posterior is not needed.

Since its introduction, herding has been shown to have many desirable properties.
For instance, Chen et al showed that the moments converge at a rate of $O(1/T^{2})$ for 
$T$ samples, which is even faster than the $O(1/T)$ that would be obtained 
by sampling independently from the exact posterior. Furthermore, \citet{Bach:2012a} show that herding is 
equivalent to conditional gradient, and \citet{Huszar:2012} show that 
herding is equivalent to Bayesian quadrature. Herding was originally conceived of as a method 
for inference in Markov random fields, and this line of work has been further explored in 
\citet{Welling:2009a}, \citet{Gelfand:2010} and \citet{Bornn:2013}.

In order to define herding, let $\sX$ be an observation space, $\phi : \sX \to \sB_{\Theta}$ a 
feature map to an inner product space, and $\bar\phi = \bE_{x \sim p}[\phi(x)]$ the empirical 
moments of some distribution. Then the herding algorithm is the following simple procedure to 
generate pseudosamples from $\sX$:
\[
x_{t} &\in \argmin_{x \in \sX} \ip{\theta_{t}}{\phi(x)} \\
\theta_{t} &= \theta_{t-1}  + \bar \phi - \phi(x_{t}).
\]
In this paper we generalize the herding algorithm to the following set of updates, which 
require only the convexity of $h$ and $R$:
\[
u_t &\in \argmin_{u} h(u) + \ip{\theta_t}{u} \\
\theta_{t+1} &\in \argmax_{\theta} \ip{\theta}{\hat{u}_t} - R(\theta),
\]
where $\hat{u}_t$ is a certain weighted average of $u_1,\ldots,u_t$. Our 
algorithm is described in more detail in Section~\ref{sec:algorithm}. This 
generalization has several advantages:
\begin{itemize}
\item It allows us to cast herding in the framework of mirror descent, 
      which lets us better understand its convergence properties.
\item It allows us to obtain generalizations of herding for infinite 
      dimensional spaces that may apply even if standard herding does not.
\item It makes the known connections between herding, subgradient, and 
      conditional gradient methods more clear. 
\end{itemize}
In particular, while it was known that herding was a form of conditional 
gradient descent \cite{Bach:2012a} and hence (via the relationship in \citet{Bach:2012b}) also 
a form of subgradient descent, our framework exposes all three algorithms 
as special cases. A full table outlining the relationships for various choices of 
$h$ and $R$ is given in Table~\ref{tab:connections}.
% -- Doesn't seem relevant enough to justify the amount of technical detail
%An alternative interpretation of herding \citep{Chen:2010a,Huszar:2012,Bach:2012a} is as a moment matching algorithm. In particular, it generates a set of pseudosamples $\{ x_{t} \}$  which match the moments $\bar\phi$. That is, the squared error $\sE_{T}^{2} \eqdef \| \bar\phi - T^{-1}\sum_{t=1}^{T} \phi(x_{t})\|^{2} \to 0$ as $T \to \infty$.  If $\sB_{\Theta}$ is a reproducing kernel Hilbert space (RKHS) with feature map $\phi$, $\sE_{T}^{2}$ is equivalent to the maximum mean discrepancy (MMD) between $p$ and the empirical distribution $\hat p_{T} \eqdef T^{-1}\sum_{t=1}^{T} \delta_{x_{t}}$ \citep{Huszar:2012}:
%\(
%\sE_{T}^{2} &= \MMD^{2}(p, \hat p_{T})  \\
%&\eqdef \sup_{\theta \in \Theta} \left|\bE_{p}\ip{\theta}{\phi(x)} - \bE_{\hat p_{T}}\ip{\theta}{\phi(x)} \right|,
%\)
%where $\Theta = \{ \theta \in \sB_{\Theta} \ | \  \|\theta\| = 1 \}$.

%If we are interested in generating samples from $p$ (or some distribution with the same moments as $p$), herding provides an attractive alternative to standard i.i.d. sampling for two reasons. First, it is deterministic, so we do not have to worry about getting ``unlucky'' and generating a set of samples that poorly represent  $p$. Second, in the case where $\sB_{\theta}$ is finite dimensional, the squared error of the herding estimator converges to zero at a rate of $O(1/T^{2})$ whereas the convergence rate of i.i.d.~sampling is $O(1/T)$ \citep{Chen:2010a}. The infinite dimensional case, however, is not as well understood. \citet{Bach:2012a} recently showed that the $O(1/T^{2})$ convergence proof of \citet{Chen:2010a} does not apply in the infinite dimensional case. In addition, \citet{Bach:2012a} introduced an interpretation of herding as a special case of conditional gradient descent (\cgd) minimizing the square norm of an RKHS. They showed that \cgd with line search leads to faster convergence rates: $O(1/T)$ in the infinite dimensional case and exponential in the finite dimensional case. However, they found  empirically that line search had poor approximation properties since led to distributions far from the maximum entropy distribution. 

In summary, we introduce a novel gradient descent algorithm to investigate herding and its generalizations, and make the following contributions:
\begin{itemize}
\item In Section \ref{sec:algorithm} we introduce a pair of convex optimization algorithms, which we call primal and dual boosted mirror descent (\primal and \dual). We show how \primal and \dual relate to \cgd and mirror descent (\md). 
\item We then use \dual in Section \ref{sec:herding} to define two classes of generalized herding algorithms. Connections with the ``learning'' interpretation of herding are made by showing how to obtain herding as the limit of an entropically normalized case of \dual. 
\item Section \ref{sec:proofs} presents convergence rates for \primal and \dual. As special cases, we recover a $O(\log T/ T)$ convergence rate for classical herding and a $O(1/T)$ rate for weighted herding. Both of these results apply to the infinite dimensional case. 
\item In Section \ref{sec:lower-bounds} we prove a matching lower bound to the upper bound given in Section \ref{sec:proofs}, showing that any ``sparse'' herding-like method cannot converge faster than $O(1/T)$ in the the infinite dimensional case.% and that herding converges at the slower $O(\log T / T)$ rate.
\item Finally, in section \ref{sec:chen} we generalize the $O(1/T^{2})$ convergence proof of \citet{Chen:2010a} to a class of herding-like algorithms derived from \bmd. 
\end{itemize}


\end{document}
