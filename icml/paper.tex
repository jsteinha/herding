%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2013 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{import, icml2013}
\input{latex-defs.tex}

\icmltitlerunning{Boosted Mirror Descent}

\begin{document} 

\twocolumn[
\icmltitle{Boosted Mirror Descent, Frank-Wolfe, and Herding}

\icmlauthor{Jacob Steinhardt}{jsteinhardt@cs.stanford.edu}
\icmladdress{Stanford University,
             353 Serra Street, Stanford, CA 94305 USA}
\icmlauthor{Jonathan Huggins}{jhuggins@mit.edu}
\icmladdress{Massachusetts Institute of Technology,
             43 Vassar Street, Cambridge, MA 02139 USA}

% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{boosting, optimization, mirror descent, frank-wolfe, herding}

\vskip 0.3in
]

\begin{abstract} 
TODO
\end{abstract} 

\section{Introduction}
\label{sec:intro}

\section{Boosted Mirror Descent}
\label{sec:algorithm}

\NA{JHH: I'm thinking that from the beginning we should let $u$ be defined over a different space than $\theta$ and assume a linear map $u \mapsto \eta(u) \in \Theta$. Then write $\langle \theta, \eta(u) \rangle$ so the setup will align with the herding case, where $\eta(u) = \bE_{u}[\phi(x)]$. }

Consider the following loss function:
\begin{equation}
L(u) = h(u) + \max_{\theta \in \Theta} \left\{\langle \theta, u \rangle - R(\theta) \right\}.
\end{equation}
We can think of $h$ as a \emph{primal regularizer} and $R$ as a \emph{dual regularizer}. 

Examples:
\begin{itemize}
\item Let $h(u) = 0$ and $R(\theta) = \langle \theta, u_0 \rangle$. Then $L(u)$ is the 
      \emph{maximum mean discrepancy} between $u$ and $u_0$ 
      relative to $\Theta$.
\item Let $h(u) = 0$ and $R(\theta) = S^*(\theta)$ where $S^*$ is the Fenchel conjugate of 
      any strongly convex function $S$. Then $L(u) = S(u)$.
\item Let $h(u) = \|u\|_1$, $R(u) = \langle \theta, u_0 \rangle + \frac{1}{2} \|\theta\|_2^2$. 
      Then $L(u) = \|u\|_1 + \frac{1}{2} \|u-u_0\|_2^2$. 
\end{itemize}

In this paper we will consider a family of methods for minimizing $L(u)$, 
which are based on Bach's generalization of the Frank-Wolfe algorithm and can 
be interpreted as boosted mirror descent.

\NA{JHH: Should we comment on the symmetry introduced by this formulation?}
First, let us generalize the setting 
to consider a \emph{two-argument} loss function
\begin{equation}
L(u,\theta) = h(u) + \langle \theta, u \rangle - R(\theta).
\end{equation}
We will assume throughout that $h$ and $R$ are both convex functions, 
and furthermore that $\arg\max_{u} h(u) + \theta^Tu$ can be efficiently 
computed for all values of $\theta$.

Mirror descent, together with boosting, yields an algorithm for finding 
``saddle points'' of $L$. It is the following algorithm (called Algorithm 1).
For notational convenience, for a sequence of weights $\alpha_1,\alpha_2,\ldots$ 
let $\hat{u}_t = \frac{\sum_{s=1}^t \alpha_su_s}{\sum_{s=1}^t \alpha_s}$ and let 
$\hat{\theta}_t = \frac{\sum_{s=1}^t \alpha_s\theta_s}{\sum_{s=1}^t \alpha_s}$.
\begin{enumerate}
\item $u_1 \in \arg\min_u h(u)$
\item $\theta_{t} \in \arg\max_{\theta \in \Theta} \langle \theta, u_t \rangle - R(\theta)$
\item $u_{t+1} \in \arg\min_{u} h(u) + \langle \hat{\theta}_t, u \rangle$
%\item $u_{t+1} \in \arg\min_{u} h(u) + \langle \frac{1}{t} \sum_{s \leq t} \theta_s, u \rangle$
\end{enumerate}
As long as $h$ is strongly convex, we obtain the 
bound (see Proposition~\ref{cor:method-1}):
\begin{equation}
\sup_{\theta \in \Theta} L(\hat{u}_T, \theta) \leq \sup_{\theta \in \Theta} L(u^*, \theta) + O(1/T).
\end{equation}
In other words, $\hat{u}_T$ is close to being a global minimum of $L$.
However, it is often the case that $h$ is not strongly convex, whereas $R$ is strongly convex. In this case 
we may wish to use the following slightly different algorithm (called Algorithm 2):
\begin{enumerate}
\item $\theta_1 \in \arg\min_{\theta} R(\theta)$
\item $u_t \in \arg\min_{u} h(u) + \langle \theta_t, u \rangle$
%\item $\theta_{t+1} \in \arg\max_{\theta \in \Theta} \langle \theta, \frac{1}{t} \sum_{s \leq t} u_s \rangle - R(\theta)$
\item $\theta_{t+1} \in \arg\max_{\theta \in \Theta} \langle \theta, \hat{u}_t \rangle - R(\theta)$
\end{enumerate}
We then obtain the following bound 
when $R$ is strongly convex (see Proposition~\ref{cor:method-2}):
\[ \sup_{\theta \in \Theta} L(\hat{u}_T, \theta) \leq \sup_{\theta \in \Theta} L(u^*, \theta) + O(1/T). \]
Algorithm 1 and Algorithm 2 are closely related; indeed, they are dual to each other 
(performing Algorithm 1 on $L(u,\theta)$ is the same as performing Algorithm 2 on 
$-L(\theta,u)$).
\NA{JHH: It would be more elegant to argue either here or below that the bounds on the second algorithm follow directly from duality}
\NA{JNS: The statements aren't actually dual to each other; the first is saying that the primal converges to its 
    optimum, and the second is saying that the dual converges to its optimum.}

\section{Convergence Proofs}
\label{sec:proofs}
We now prove the convergence results cited in Section~\ref{sec:algorithm}. 
We start with two preliminary lemmas.
\begin{lemma}
\label{lem:ftl}
Let $l_1,\ldots,l_T$ be functions of $x$ and let $x_1,\ldots,x_T$ 
be chosen via $x_{t+1} \in \arg\min_{x} \frac{1}{t} \sum_{s \leq t} l_s(x)$. 
Then for any $x^*$ we have
\[ \sum_{t=1}^T l_t(x_t) \leq \sum_{t=1}^T l_t(x^*) + \sum_{t=1}^T (l_t(x_t) - l_t(x_{t+1})). \]
\end{lemma}
\begin{proof}
\NA{JHH: Doesn't rely on the spaces $x$'s having any structure nor on any properties of the functions.}
Re-arranging, we want to show that $\sum_{t=1}^T l_t(x_{t+1}) \leq \sum_{t=1}^T l_t(x^*)$ for 
all $x^*$. We will show this by induction. In the base case $T=1$, we want to show that $l_1(x_2) \leq l_1(x^*)$ 
for all $x^*$, which is true because $x_2 \in \argmin_x l_1(x)$ by construction. For 
the inductive step, suppose that the result holds for $T-1$:
\[ \sum_{t=1}^{T-1} l_t(x_{t+1}) \leq \sum_{t=1}^T l_t(x^*). \]
Now set $x^* = x_{T+1}$ in the above inequality and 
add $l_T(x_{T+1})$ to both sides to get
\begin{align*}
\sum_{t=1}^T l_t(x_{t+1}) &\leq \sum_{t=1}^T l_t(x_{T+1}) \\
 &= \min_{x} \sum_{t=1}^T l_t(x) \\
 &\leq \sum_{t=1}^T l_t(x^*),
\end{align*}
which completes the induction. Here we are using the fact that $x_{T+1}$ 
is the minimizer of $\frac{1}{T} \sum_{t=1}^T l_t(x)$ and hence also of 
$\sum_{t=1}^T l_t(x)$.
\end{proof}
\begin{lemma}
\label{lem:convexity}
Suppose that $f(x)$ is \emph{$\alpha$-strongly convex}: $f(x) \geq f(x_0) + \partial f(x_0)^T(x-x_0) + \frac{\alpha}{2}\|x-x_0\|^2$. 
Let $F(y) := \arg\min_x f(x) + y^Tx$. Then $\|F(y_0)-F(y_1)\| \leq \frac{2}{\alpha} \|y_0-y_1\|$.
\end{lemma}
\begin{proof}
\NA{JHH: Follows from $f$ being strongly convex, the definition of inner product, and Cauchy-Schwartz. We'll just want to be careful about calculating $\alpha$ for our regularizer later on.}
Let $x_0 = F(y_0)$. Then we must have $\partial f(x_0) = -y_0$, hence 
\begin{align*}
f(x)+y_1^Tx &\geq f(x_0) + y_1^Tx_0 - y_0^T(x-x_0) + \frac{\alpha}{2}\|x-x_0\|^2.
\end{align*}
But any minimizer of $f(x) + y_1^Tx$ must at least have a value less than $f(x_0) + y_1^Tx_0$. 
It follows that 
\begin{align*}
         & y_1^Tx_0 \geq y_1^Tx_1 - y_0^T(x_1-x_0) + \frac{\alpha}{2}\|x_1-x_0\|^2 \\
\implies & (y_1-y_0)^T(x_0-x_1) \geq \frac{\alpha}{2}\|x_1-x_0\|^2 \\
\implies & \|y_1-y_0\|\|x_0-x_1\| \geq \frac{\alpha}{2}\|x_1-x_0\|^2 \\
\implies & \|x_1-x_0\| \leq \frac{2}{\alpha} \|y_1-y_0\|,
\end{align*}
as was to be shown.
\end{proof}
\begin{proposition}[Convergence of Algorithm 1]
\label{prop:method-1}
Consider the updates $\theta_t \in \arg\max_{\theta} \langle \theta, u_t \rangle - R(\theta)$ 
and $u_{t+1} \in \arg\min_u h(u) + \langle \hat{\theta}_s, u \rangle$. 
Then we have
\[ \sup_{\theta} L(\hat{u}_T, \theta) \leq \sup_{\theta} L(u^*, \theta) + \frac{\sum_{t=1}^T \alpha_t \langle u_t - u_{t+1}, \theta_t \rangle}{\sum_{t=1}^T \alpha_t}. \]
\end{proposition}
\begin{proof}
\NA{JHH: Uses, Lemma~\ref{lem:ftl}, convexity of $h$, taking supremums, and facts that follow from the construction of the algorithm.}
Note that $L(u_t, \theta_t) = \max_{\theta} L(u_t, \theta)$ by construction. Also note that, if we invoke 
Lemma~\ref{lem:ftl} with $l_t(u) = \alpha_t L(u, \theta_t)$, then we get the inequality
\[ \sum_{t=1}^T \alpha_t L(u_t, \theta_t) \leq \sum_{t=1}^T \alpha_t L(u^*, \theta_t) + \sum_{t=1}^T \alpha_t \langle u_t - u_{t+1}, \theta_t \rangle. \]
Combining these together, we get the string of inequalities
\begin{align*}
L(\hat{u}_T, \theta) &= L\left(\frac{\sum_{t=1}^T \alpha_tu_t}{\sum_{t=1}^T \alpha_t}, \theta\right) \\
 &\leq \frac{\sum_{t=1}^T \alpha_t L(u_t, \theta)}{\sum_{t=1}^T \alpha_t} \\
 &\leq \frac{\sum_{t=1}^T \alpha_t L(u_t, \theta_t)}{\sum_{t=1}^T \alpha_t} \\
 &\leq \frac{\sum_{t=1}^T \alpha_tL(u^*, \theta_t)}{\sum_{t=1}^T \alpha_t} \\ &\phantom{=} + \frac{\sum_{t=1}^T \alpha_t (L(u_t,\theta_t)-L(u_{t+1},\theta_t))}{\sum_{t=1}^T \alpha_t} \\
 &= L(u^*, \theta_t) + \frac{\sum_{t=1}^T \alpha_t \langle u_t - u_{t+1}, \theta_t \rangle)}{\sum_{t=1}^T \alpha_t} \\ &\phantom{=} + \frac{\sum_{t=1}^{T} \alpha_t(h(u_t)-h(u_{t+1}))}{\sum_{t=1}^T \alpha_t} \\
 &= L(u^*, \theta_t) + \frac{\sum_{t=1}^T \alpha_t \langle u_t - u_{t+1}, \theta_t \rangle}{\sum_{t=1}^T \alpha_t} \\ &\phantom{=} + \frac{\alpha_1 h(u_1) - \alpha_T h(u_{T+1}) + \sum_{t=2}^{T} (\alpha_t-\alpha_{t-1}) h(u_t)}{\sum_{t=1}^T \alpha_t} \\
 &\leq L(u^*, \theta_t) + \frac{\sum_{t=1}^T \alpha_t \langle u_t - u_{t+1}, \theta_t \rangle}{\sum_{t=1}^T \alpha_t} \\
 &\leq \sup_{\theta} L(u^*, \theta) + \frac{\sum_{t=1}^T \alpha_t \langle u_t - u_{t+1}, \theta_t \rangle}{\sum_{t=1}^T \alpha_t},
\end{align*}
as was to be shown.
\end{proof}
\begin{corollary}
\label{cor:method-1}
Suppose that $h$ is $\gamma$-strongly convex and let $r = \sup_{\theta} |\langle \theta, \theta \rangle|_2$. Then 
\[ \sup_{\theta} L(\hat{u}, \theta) \leq \sup_{\theta} L(u^*, \theta) + \frac{16r^2}{\gamma T^2}. \]
\end{corollary}
\begin{proof}
\NA{JHH: Follows from Lemma~\ref{lem:convexity}, triangle inequality, taking supremums, and Cauchy-Schwartz.}
By Lemma~\ref{lem:convexity}, we have 
\begin{align*}
\|u_t-u_{t+1}\| &\leq \frac{2}{\gamma}\|\frac{\sum_{s \leq t}\alpha_s\theta_s}{\sum_{s \leq t} \alpha_s} - \frac{\sum_{s \leq t+1}\alpha_s\theta_s}{\sum_{s \leq t+1} \alpha_s}\| \\
 &= \frac{2}{\gamma}\|\frac{\alpha_{t+1}}{A_tA_{t+1}} \sum_{s \leq t} \alpha_s\theta_s - \frac{\alpha_{t+1}}{A_{t+1}} \theta_{t+1}\| \\
 &\leq \frac{2}{\gamma} \left(\frac{\alpha_{t+1}}{A_tA_{t+1}} \sum_{s \leq t} \alpha_s\|\theta_s\| + \frac{\alpha_{t+1}}{A_{t+1}} \|\theta_{t+1}\|\right) \\
 &\leq \frac{4r\alpha_{t+1}}{\gamma A_{t+1}}.
\end{align*}
It follows from Cauchy-Schwartz that 
\begin{align*}
\frac{1}{A_T} \sum_{t=1}^T \alpha_t \langle u_t - u_{t+1}, \theta_t \rangle &\leq \sum_{t=1}^T \frac{4r^2\alpha_{t}\alpha_{t+1}}{\gamma A_{t+1}A_T} \\
 &\leq \frac{4r^2}{\gamma A_T} \sum_{t=1}^T \frac{\alpha_{t}\alpha_{t+1}}{A_{t+1}}.
\end{align*}
In particular, if we let $\alpha_t = t$, then $A_t = \frac{t(t+1)}{2}$ and $\frac{\alpha_{t}\alpha_{t+1}}{A_{t+1}} = 2$. 
We therefore get
\begin{equation}
\frac{1}{A_T} \sum_{t=1}^T \alpha_t\langle u_t-u_{t+1}, \theta_t \rangle \leq \frac{16r^2}{T(T+1)},
\end{equation}
which completes the proof.
\end{proof}
\begin{proposition}[Convergence of Algorithm 2]
\label{prop:method-2}
Consider the updates $u_t \in \arg\min_{u} h(u) + \langle \theta_t, u \rangle$ 
and $\theta_{t+1} \in \arg\max_{\theta} \langle \theta, \frac{1}{t} \sum_{s \leq t} u_s \rangle - R(\theta)$. 
Then for $\hat{u} = \frac{1}{T} \sum_{t=1}^T u_t$, we have 
\[ \sup_{\theta} L(\hat{u}, \theta) \leq \sup_{\theta} L(u^*, \theta) + \frac{1}{T} \sum_{t=1}^T \langle u_t, \theta_{t+1} - \theta_{t} \rangle. \]
\end{proposition}
\begin{proof}
If we invoke Lemma~\ref{lem:ftl} with $l_t(\theta) = -L(u_t, \theta)$, then we get the inequality
\[ \sum_{t=1}^T -L(u_t, \theta_t) \leq -\sum_{t=1}^T L(u_t, \theta^*) - \sum_{t=1}^T \langle u_t, \theta_t - \theta_{t+1} \rangle. \]
Re-arranging yields
\[ \sum_{t=1}^T L(u_t, \theta^*) \leq \sum_{t=1}^T L(u_t, \theta_t) + \sum_{t=1}^T \langle u_t, \theta_{t+1} - \theta_t \rangle. \]
Now, we have the following string of inequalities:
\begin{align*}
L(\hat{u}, \theta) &= L\left(\frac{1}{T} \sum_{t=1}^T u_t, \theta\right) \\
 &\leq \frac{1}{T} \sum_{t=1}^T L(u_t, \theta) \\
 &\leq \frac{1}{T} \sum_{t=1}^T L(u_t, \theta_t) + \frac{1}{T} \sum_{t=1}^T \langle u_t, \theta_{t+1} - \theta_t \rangle \\
 &= \frac{1}{T} \sum_{t=1}^T \inf_{u} L(u, \theta_t) + \frac{1}{T} \sum_{t=1}^T \langle u_t, \theta_{t+1} - \theta_t \rangle \\
 &\leq \frac{1}{T} \sum_{t=1}^T L(u^*, \theta_t) + \frac{1}{T} \sum_{t=1}^T \langle u_t, \theta_{t+1} - \theta_t \rangle \\
 &\leq \frac{1}{T} \sum_{t=1}^T \sup_{\theta} L(u^*, \theta) + \frac{1}{T} \sum_{t=1}^T \langle u_t, \theta_{t+1} - \theta_t \rangle \\
 &= \sup_{\theta} L(u^*, \theta) + \frac{1}{T} \sum_{t=1}^T \langle u_t, \theta_{t+1} - \theta_t \rangle,
\end{align*}
as was to be shown.
\end{proof}
\begin{corollary}
\label{cor:method-2}
Suppose that $R$ is $\gamma$-strongly convex and let $r = \sup_{u} |\langle u, u \rangle|$. Then
\[ \sup_{\theta} L(\hat{u}, \theta) \leq \sup_{\theta} L(u^*, \theta) + \frac{16r^2}{\gamma T^2}. \]
\end{corollary}
\begin{proof}
The proof is identical to the previous corollary.
\end{proof}

\section{Application to Herding}
\label{sec:herding}

\NA{JHH: Need to specify the spaces we are working with here.}
Suppose we are given a family of features $\phi$ together 
with a known value $\bar{\phi}$ for $\bE_{\mu}[\phi]$. We 
would like to construct a distribution that approximately 
matches this distribution, i.e.~one for which 
$\bE_{\hat{\mu}}[\phi] \approx \bar{\phi}$. A natural way 
to do this is by using boosted mirror descent to minimize the 
maximum mean discrepancy relative to $\phi$; 
in other words, to minimize
\[ L(\mu) = \max_{i \in \{1,\dots,d\}} |\bE_{\mu}[\phi_i]-\bar{\phi}_i|. \]
If we wish to write this more similarly to the original problem 
formulation, we can write
\[ L(\mu) = \sup_{\|\theta\|_1 \leq 1} \theta^T(\bE_{\mu}[\phi]-\bar{\phi}). \]
One issue is that $\|\theta\|_1$ is not strongly convex, so we relax $\|\theta\|_1$ 
to $\|\theta\|_2$ and write our loss function in the Lagrangian form:
\[ L(\mu, \theta) = \theta^T\bE_{\mu}[\phi] - \theta^T\bar{\phi} - \frac{1}{2}\|\theta\|_2^2. \]
Intriguingly, Algorithm 1 and Algorithm 2 are identical to each other for this choice of $L$ 
(up to a change of index). In this case, $\mu_t = \delta_{x_t}$ for some $x_t$, and 
the updates are the same as the standard herding updates. Let $r = \sup_{x} \|\phi(x)\|_2$; 
then using the Algorithm 2 convergence bound gives us
\begin{align*}
\sup_{\theta} L\left(\frac{1}{T} \sum_{t=1}^T \delta_{x_t}, \theta\right) &\leq \inf_{u^*} \sup_{\theta} L(u^*, \theta) + \frac{2R^2\log(T+1)}{T} \\
 &= \sup_{\theta} \inf_{u^*} L(u^*, \theta) + \frac{2R^2\log(T+1)}{T} \\
 &= \frac{2R^2\log(T+1)}{T}.
\end{align*}
This is a slightly weaker version of the typical herding bound on MMD.

\section{Herding in Infinite Dimensions}
\label{sec:infinite-case}

\section{Herding and Maximum Entropy}
\label{sec:max-ent}

Let us now consider the entropic regularizer $h(u) = \tau\bE_{u}[\log u(x)]$ with 
\[ R(\theta) = \bE_{u}[\theta^T\bar{\phi}] + \left\{ \begin{array}{llc} \infty & : & \|\theta\|_1 > 1 \\ 0 & : & \|\theta\|_1 \leq 1 \end{array} \right.\]
If we use Method 1, we then end up with 
\[ u_{t}(x) \propto \exp\left\{-\frac{1}{\alpha}\overline{\theta}_{t}^T\phi(x)\right\}, \]
where $\overline{\theta}_{t} = \frac{1}{t} \sum_{s \le t} \theta_{s}$. Hence, $h(u) + \bE_{\mu}[\theta^T\phi(x)] - R(\theta)$ is no longer maximized at the boundary (when $\tau > 0$). We can instead consider the following sequence of distributions:
\begin{enumerate}
\item $\theta_t \in \argmax_{\|\theta\|_1 \leq 1} \theta^T (\bE_{u_t}[\phi(x)]-\bar{\phi})$
\item $u_{t+1}(x) = Z(\overline{\theta}_{t}, \tau)^{-1} \exp\left\{-\frac{1}{\tau}\overline{\theta}_{t}^T\phi(x)\right\}$
\end{enumerate}
Here $Z(\overline{\theta}_{t}, \tau) = \int\exp\left\{-\frac{1}{\tau}\overline{\theta}_{t}^T\phi(x)\right\} \dee x$. 

The entropic regularizer is not strongly convex but a more general analysis involving 
Bregman divergence can nevertheless yield a convergence bound in this case. We thus 
get something that looks like herding but actually gives us an exponential family 
type distribution. In particular, we have a Gibbs distribution with temperature $\tau$, and 
in the limit as the temperature goes to zero, we recover herding, since 
\[ \lim_{\tau \to 0} u_{t+1}(x) = \delta_{x^{*}_{t+1}}, \]
where $x^{*}_{t+1} = \argmin_{x} \overline{\theta}_{t}^T\phi(x)$. 
This fact is reminiscent of Welling's original derivation of herding, in which 
he took the zero temperature limit of the gradient descent algorithm for the optimization problem 
\[ \argmin_{u} h(u) \quad \text{s.t.}~\bE_{u}[\phi(x)] - \bar\phi = 0. \]
This optimization is quite similar to the entropic optimization considered here, which 
we can write as 
\begin{align*}
\argmin_{u}& \argmax_{|\theta\|_1 \leq 1} h(u) + \theta^{T}(\bE_{u}[\phi(x)] - \bar \phi)  \\
&= \argmin_{u} h(u) + \|\bE_{u}[\phi(x)] - \bar\phi\|_{2}. 
\end{align*}
In the entropic formulation, the expectation constraint $\bE_{u}[\phi(x)] - \bar\phi = 0$ becomes
soft, though the two optimizations are equivalent in the zero-temperature limit. 

We can view the entropic regularization
with non-zero temperature as an alternative approximation to herding. If at each step we
retain a sample $x_{t} \sim u_{t}$, then the sequence $(x_{t})_{t}$ converges to the 
herding sample path as $\tau \to 0$. So $(x_{t})_{t}$ with non-zero temperature approximate
herding samples. \NA{JHH: I'm not sure how useful this all is, other than to make contact with 
the original paper, as I think the Gibbs distribution was exactly what Max was trying to 
avoid by taking the zero-temperature limit.}

\section{Conclusion}
\label{sec:conclusion}

%\bibliography{example_paper}
%\bibliographystyle{icml2013}

\end{document} 


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  
