\documentclass[paper.tex]{subfiles}
\begin{document}

\section{Boosted Mirror Descent}
\label{sec:algorithm}

Our results primarily rely on a pair of novel convex optimization algorithms we call primal and dual boosted mirror descent. 

\subsection{Convex Optimization}

Before introducing the boosted mirror descent (\bmd) algorithms, we recall some basic definitions related convex optimization. Let $f$ be a real function whose domain is a Banach space. The {\em convex conjugate} $f^{*}$ of $f$ is defined as
\[
f^{*}(y) \eqdef \max_{x} \ip{x}{y} - f(x).
\]
If $f$ is lower semi-continuous, then by the Fenchel-Moreau theorem $f = f^{**}$, i.e.
\[
f(x) = \max_{y} \ip{x}{y} - f^{*}(y).
\]
Throughout the paper, we will assume without further notice that functions are lower semi-continuous when required. The gradients of $f^{*}$ and $f$ can be defined as any argument that maximizes the previous two equations:
\[
\partial f^{*}(y) &\in \argmax_{x} \ip{x}{y} - f(x) \\
\partial f(x) &\in \argmax_{y} \ip{x}{y} - f^{*}(y).
\]

In order to prove fast convergence, we will require additional assumptions beyond convexity. We say a function $f$ is {\em $\alpha$-strongly convex} if 
\[
f(x)  - f(y) \le \ip{\partial f(x)}{x-y} - \frac{\alpha}{2}\|x - y\|^{2}.
\]
and that a (possibly non-convex) function $g$ is $\beta$-smooth if 
\[
\|\partial g(x) - \partial g(y) \| \le \beta \| x - y\|.
\]
Strong convexity and smoothness are dual to each in the sense that a convex function $f$ is $\alpha$-strongly convex if and only if $f^{*}$ is $(1/\alpha)$-smooth.

\subsection{The Boosted Mirror Descent Algorithms}

We can now define the \bmd  algorithms. Let $U$ and $\Theta$ be convex subsets of the Banach spaces $\sB_{U}$ and $\sB_{\Theta}$, respectively, and let $\imath : U \to \Theta$ be a linear imbedding from $U$ to $\Theta$ that preserves the inner product. Consider the two-argument loss function $L : U \times \Theta \to \bR$ 
\[
L(u,\theta) = h(u) + \ip{\theta}{\imath(u)} - R(\theta)
\]
for which we wish to find arguments that obtain $L_{*} = \min_{u}\max_{\theta} L(u, \theta)$. Taking only max, we have the one-argument loss function:
\[
L(u)
&= h(u) + \max_{\theta \in \Theta} \left\{\ip{\theta}{\imath(u)} - R(\theta) \right\} \\
&= h(u) + R^{*}(\imath(u)).
\]
We can think of $h$ as a \emph{primal regularizer} and $R$ as a \emph{dual regularizer}.  The pair of regularization functions $h$ and $R$ provides flexible optimization framework, as seen from the following examples:
\begin{enumerate}
\item Let $U$ be the probability simplex over a space $\sX$, let $\phi : \sX \to \bR^d$ be a collection 
      of statistics, and let $\Theta$ be the unit $L^1$ ball in $\bR^d$. Let $h(u) = 0$, 
      $\langle \theta, \imath(u) \rangle = \bE_u[\theta^T\phi(x)]$, and 
      $R(\theta) = \langle \theta, \imath(u_0) \rangle$. Then $L(u)$ is the 
      \emph{maximum mean discrepancy} between $u$ and $u_0$ relative to $\phi$.
\item Let $h(u) = 0$ and $R(\theta) = S^*(i^{-1}(\theta))$ where $S^*$ is the 
      convex conjugate of any strongly convex function $S : U \to \bR$. Then $L(u) = S(u)$ 
      as long as $i^{-1}(\Theta) = \sB_{U}$.
\item Let $U = \Theta = \bR^d$ and $\imath$ the identity map. Let $h(u) = \|u\|_1$, $R(u) = \langle \theta, u_0 \rangle + \frac{1}{2} \|\theta\|_2^2$. 
      Then $L(u) = \|u\|_1 + \frac{1}{2} \|u-u_0\|_2^2$. 
\end{enumerate}

Going forward, for convenience we will abuse notation and use $\ip{\theta}{u}$ in place of 
$\ip{\theta}{\imath(u)}$ when the map $\imath$ is clear from context. We will assume 
throughout that $h$ and $R$ are both convex functions, and furthermore that 
$\arg\max_{u} h(u) + \ip{\theta}{u}$ can be efficiently 
computed for all values of $\theta$.

%In this paper we will consider a family of methods for minimizing $L(u)$, 
%which are based on Bach's generalization of the Frank-Wolfe algorithm and can 
%be interpreted as boosted mirror descent.

Mirror descent, together with boosting, yields an algorithm for finding 
``saddle points'' of $L$. 
For notational convenience, for a sequence of weights $\alpha_1,\alpha_2,\ldots$ 
let $\hat{u}_t = \frac{\sum_{s=1}^t \alpha_su_s}{\sum_{s=1}^t \alpha_s}$ and let 
$\hat{\theta}_t = \frac{\sum_{s=1}^t \alpha_s\theta_s}{\sum_{s=1}^t \alpha_s}$. Then 
the {\em primal boosted mirror descent} (\primal) algorithm is:
\begin{enumerate}
\item $u_1 \in \arg\min_u h(u)$
\item $\theta_{t} \in \arg\max_{\theta \in \Theta} \langle \theta, u_t \rangle - R(\theta) = \partial R^{*}(u_{t})$
\item $u_{t+1} \in \arg\min_{u} h(u) + \langle \hat{\theta}_t, u \rangle = \partial h^{*}(-\hat\theta_{t})$
\end{enumerate}
As long as $h$ is strongly convex, we obtain the 
bound (see Corollary~\ref{cor:method-1}):
\begin{equation}
\sup_{\theta \in \Theta} L(\hat{u}_T, \theta) \leq L_{*} + O(1/T).
\end{equation}
In other words, $\hat{u}_T$ is close to being a global minimum of $L(u)$.
However, it is often the case that $h$ is not strongly convex, whereas $R$ is strongly convex. As we shall see, this will be the case for our application to herding.
In this case we may wish to use the following slightly different algorithm, which we call {\em dual boosted mirror descent} (\dual):
\begin{enumerate}
\item $\theta_1 \in \arg\min_{\theta} R(\theta)$
\item $u_t \in \arg\min_{u} h(u) + \langle \theta_t, u \rangle = \partial h^{*}(-\theta_{t})$
\item $\theta_{t+1} \in \arg\max_{\theta \in \Theta} \langle \theta, \hat{u}_t \rangle - R(\theta) = \partial R^{*}(\hat u_{t})$
\end{enumerate}
We then obtain the following bound 
when $R$ is strongly convex (see Corollary~\ref{cor:method-2}):
\[ \sup_{\theta \in \Theta} L(\hat{u}_T, \theta) \leq L_{*} + O(1/T). \]
As suggested by the name \primal and \dual are closely related; indeed, they are dual to each other in the sense that 
performing \primal on $L(u,\theta)$ is the same as performing \dual on 
$-L(\theta,u)$.


\subsection{Connections to Other Gradient Descent Algorithms}

The \bmd algorithms are very closely related to \cgd and \md. 

\end{document}
