\documentclass[paper_icml.tex]{subfiles}
\begin{document}

\section{Choosing $m_t$ via Follow the Regularized Leader} 
\label{sec:ftrl-aux}
In the previous section we introduced an adaptive exponentiated 
gradient algorithm that achieved a regret bound of 
\[ \frac{\log(n)}{\eta} + \eta \sum_{i=1}^n w_i \sum_{t=1}^T (z_{t,i} - m_{t,i})^2 \]
for any sequence $m_t$. We now turn our attention to the task of 
optimizing $m_t$. Clearly, the optimal value of $m_t$ is $m_t = z_t$. However, 
this would require perfect knowledge of the future. Suppose we are less ambitious 
and only want to be competitive with the best fixed value of $m_t$. This optimal value 
is $m^* \eqdef \frac{1}{T} \sum_{t=1}^T z_t$, but we still have the issue that 
we do not know $m^*$ ahead of time. However, we have now cast the problem in the familiar 
regret minimzation framework, and can use the machinery of follow the regularized 
leader \cite{hazan2011ftrl} to prove:
\begin{proposition}
\label{prop:ftrl-aux}
Suppose that we choose $m_{t,i} = \frac{1}{t} \sum_{s=1}^{t-1} z_{s,i}$ and that 
$\|z_s\|_{\infty} \leq 1$. Then for all $i$ we have
\[ \sum_{t=1}^T (z_{t,i} - m_{t,i})^2 \leq 2\sum_{t=1}^T (z_{t,i} - m^*_i)^2 + 6. \]
\end{proposition}
\begin{proof}
Note that $m_{t,i}$ is the minimizer of $m_i^2 + \sum_{s=1}^{t-1} (z_{s,i} - m_i)^2$. 
Therefore, by the FTRL lemma, we have
\begin{align*}
\lefteqn{\sum_{t=1}^T (z_{t,i}-m_{t,i})^2 - (z_{t,i} - m^*_i)^2} \\
 &\leq (m^*_i)^2 + \sum_{t=1}^T (z_{t,i}-m_{t,i})^2 - (z_{t,i} - m_{t+1,i})^2 \\
 &= (m^*_i)^2 + \sum_{t=1}^T 2z_{t,i}(m_{t+1,i}-m_{t,i}) + m_{t,i}^2 - m_{t+1,i}^2 \\
 &= (m^*_i)^2 + m_{1,i}^2 - m_{T+1,i}^2 + \sum_{t=1}^T \frac{2}{t+1}z_{t,i}(z_{t,i} - m_{t,i}) \\
 &\leq 1 + \sum_{t=1}^T \frac{z_{t,i}^2}{\gamma (t+1)^2} + \gamma(z_{t,i} - m_{t,i})^2 \\
 &\leq 1 + \frac{1}{\gamma} + \gamma \sum_{t=1}^T (z_{t,i} - m_{t,i})^2.
\end{align*}
Re-arranging yields
\begin{equation*}
\sum_{t=1}^T (z_{t,i} - m_{t,i})^2 \leq \frac{1}{1-\gamma}\left(\frac{1+\gamma}{\gamma} + \sum_{t=1}^T (z_{t,i} - m_i^*)^2\right),
\end{equation*}
which for $\gamma = \frac{1}{2}$ yields the desired result.
\end{proof}
Combining Proposition~\ref{prop:ftrl-aux} with Proposition~\ref{prop:aeg} yields 
the algorithm titled EG-Variance in Table~\ref{tab:algorithms}. This algorithm has the 
same updates as the algorithm given by \cite{hazan2010variation}, but uses the 
optimistic prediction $\exp(\theta_t - \eta m_t)$ rather than $\exp(\theta_t)$. 
As a straightforward consequence of Propositions~\ref{prop:aeg} and~\ref{prop:ftrl-aux}, we 
obtain the following regret bound, which improves the bound presented in 
\cite{hazan2010variation}:
\begin{corollary}
\label{cor:EG-variance}
For $0 < \eta \leq \frac{1}{4}$ and $\|z_t\|_{\infty} \leq 1$, the EG-Variance 
algorithm achieves a regret bound of
%\[ \Regret(w) \leq \frac{1 + (\log(n)-1)\|w\|_1 + \sum_{i=1}^n w_i\log(w_i)}{\eta} + \eta \left[ \sum_{i=1}^n w_i \sum_{t=1}^T (z_{t,i} - m_i^*)^2 + 4\|w\|_1\log(T+1) \right]. \]
\begin{equation*}\Regret(w) \leq \frac{\log(n)}{\eta} + \eta \left[ 2\sum_{i=1}^n w_i \sum_{t=1}^T (z_{t,i} - m_i^*)^2 + 6 \right].\end{equation*} 
\end{corollary}

\end{document}
